{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744baa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecccfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x184c26b02e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e6dc3",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "* Lemmatization is convert a text or word to it's root form.\n",
    "* SpaCy provide robust solution for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ec3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "love\n",
      "walk\n",
      "in\n",
      "the\n",
      "rain\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text = 'He loved walking in the rain.'\n",
    "nile = nlp(text)\n",
    "\n",
    "for token in nile:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67666f91",
   "metadata": {},
   "source": [
    "### String to Hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1177c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6597542354426545486"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = nlp('I love reading')\n",
    "\n",
    "# check hash for the word of 'reading'\n",
    "hash_no = nlp.vocab.strings['reading']\n",
    "hash_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5f4a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reading'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now using hash_no get the string\n",
    "string = nlp.vocab.strings[hash_no]\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed4e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348f36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My -- 16248400320781648534\n",
      "girlfriend -- 4668896997415073472\n",
      "bought -- 5204146470106475914\n",
      "me -- 18197037023634208128\n",
      "a -- 11901859001352538922\n",
      "shirt -- 682501080797652416\n"
     ]
    }
   ],
   "source": [
    "gf1 = nlp('My girlfriend bought me a shirt')\n",
    "gf2 = nlp('I bought a shirt today')\n",
    "\n",
    "for token in gf1:\n",
    "    hash_val = nlp.vocab.strings[token.text]\n",
    "    print(token.text, '--', hash_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feda95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -- 4690420944186131903\n",
      "bought -- 5204146470106475914\n",
      "a -- 11901859001352538922\n",
      "shirt -- 682501080797652416\n",
      "today -- 11042482332948150395\n"
     ]
    }
   ],
   "source": [
    "for token in gf2:\n",
    "    hash_val = nlp.vocab.strings[token.text]\n",
    "    print(token.text, '--', hash_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbc488",
   "metadata": {},
   "source": [
    "### we can clearly see that, some words hash value is the same which save memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "483ad508",
   "metadata": {},
   "source": [
    "### Lexical Attributes\n",
    "* is_punct, is_space is attributes in text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c35d0615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    }
   ],
   "source": [
    "line = '2022 was my revolution year.'\n",
    "\n",
    "doc = nlp(line)\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a31e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3500\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "salary = \"Stark's passive income monthly 3000$ where Emily's monthly income 3500$, But she earn much more than sara, 3200$\"\n",
    "\n",
    "sal = nlp(salary)\n",
    "\n",
    "for token in sal:\n",
    "    if token.like_num:\n",
    "        index_token = token.i + 1\n",
    "        next_token = sal[index_token]\n",
    "        \n",
    "        if next_token.text == '$':\n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836c1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1a59b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakil1emperor@gmail.com\n",
      "chamiya.binte@gmail.com\n"
     ]
    }
   ],
   "source": [
    "bio = \"\"\"name: Shakil age: 25 email: shakil1emperor@gmail.com\n",
    "         name: Chamiya age: 23 email: chamiya.binte@gmail.com\"\"\"\n",
    "\n",
    "bio_doc = nlp(bio)\n",
    "\n",
    "for token in bio_doc:\n",
    "    if token.like_email:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c7da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
