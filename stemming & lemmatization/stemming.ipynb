{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c0b62e",
   "metadata": {},
   "source": [
    "## Stemming is used for analyze the meaning behind a word. used by search engines and chatbots to analyze. \n",
    "\n",
    "#### Stemming uses the stem of the word. It is an algorithm to do stemming.\n",
    "\n",
    "#### Stemming is basically removing the suffix from a word and reduce it to its root word.  Stemming is a process of linguistic normalization. \n",
    "\n",
    "### Main aim is reducing the inflectional forms of each word into a common base or root. \n",
    "\n",
    "### Inflection is a process of word formation, in which a word is modified to express different grammatical categories such as tense, case, voice, aspect, person, number, gender, mood, animacy, and definiteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6cad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb387a8",
   "metadata": {},
   "source": [
    "#### How does it work? \n",
    "#### Stemming algorithms work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4daf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we used some common stemming techniques\n",
    "\n",
    "1. Porter Stemmer — specific for the English language\n",
    "2. Snowball Stemmer — used for multiple languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb808fe",
   "metadata": {},
   "source": [
    "### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24eb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going ---> go\n",
      "walking ---> walk\n",
      "walks ---> walk\n"
     ]
    }
   ],
   "source": [
    "# PorterStemmer is good and fast but not the best\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "port = PorterStemmer()\n",
    "\n",
    "words = ['going', 'walking', 'walks']\n",
    "\n",
    "for w in words:\n",
    "    print(w, '--->', port.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8616f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60780a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Absorb--->: absorb\n",
      "Word: what--->: what\n",
      "Word: is--->: is\n",
      "Word: useful,--->: useful,\n",
      "Word: discard--->: discard\n",
      "Word: what--->: what\n",
      "Word: is--->: is\n",
      "Word: not,--->: not,\n",
      "Word: add--->: add\n",
      "Word: what--->: what\n",
      "Word: is--->: is\n",
      "Word: uniquely--->: uniqu\n",
      "Word: your--->: your\n",
      "Word: own.--->: own.\n"
     ]
    }
   ],
   "source": [
    "# using function\n",
    "\n",
    "philosophy = 'Absorb what is useful, discard what is not, add what is uniquely your own.'\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(sentence, model=stemmer):\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        stem = model.stem(word)\n",
    "        print('Word: {}--->: {}'.format(word, stem))\n",
    "\n",
    "stem_words(philosophy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528026a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History ---> histori\n",
      "is ---> is\n",
      "the ---> the\n",
      "best ---> best\n",
      "subject ---> subject\n",
      "for ---> for\n",
      "teaching ---> teach\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "sent = 'History is the best subject for teaching'\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "\n",
    "for t in tokens:\n",
    "    print(t, '--->', porter_stemmer.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180086a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f94e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'sit', 'on', 'my', 'lap', 'while', 'work', 'in', 'the', 'garden', '.', 'then', 'he', 'saw', 'bird', 'fli', 'in', 'the', 'sky', '.', 'i', 'wa', 'look', 'at', 'my', 'cat', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "quotes = \"The cat sits on my lap while working in the garden. Then he saw birds flying in the sky. I was looking at my cat.\"\n",
    "token = word_tokenize(quotes)\n",
    "\n",
    "port = PorterStemmer()\n",
    "stemming_words = []\n",
    "for w in token:\n",
    "    stemming_words.append(port.stem(w))\n",
    "print(stemming_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6cfad",
   "metadata": {},
   "source": [
    "#### We can clearly see that  \n",
    "flying ---> fli \n",
    "\n",
    "was ---> wa\n",
    "#### This is something which should be considered under less precise algorithm.\n",
    "\n",
    "#### To increase the precision another algorithm came which was SnowBall Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc38fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae593a55",
   "metadata": {},
   "source": [
    "### Snowball Stemmer/ English Stemmer/ Porter2 Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b354d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['provis', 'maximum', 'multipli', 'owe', 'care', 'on', 'go', 'gone', 'go', 'was', 'this']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "line = 'Provision Maximum multiply owed caring on go gone going was this'\n",
    "\n",
    "word = word_tokenize(line)\n",
    "\n",
    "after_using_snowball = [snowball.stem(w) for w in word]\n",
    "print(after_using_snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7e2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how it handled 'was' !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3b0bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(snowball.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff422107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77db9bac",
   "metadata": {},
   "source": [
    "### Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a29fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go : go\n",
      "going : going\n",
      "gone : gon\n"
     ]
    }
   ],
   "source": [
    "# It is too much aggresive algorithm than porter stemmer\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lan = LancasterStemmer()\n",
    "\n",
    "words = ['go', 'going', 'gone']\n",
    "\n",
    "for w in words:\n",
    "    print(w, ':', lan.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85b28553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'wil', 'tak', 'car', 'of', 'him', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I will take care of him.'\n",
    "token = word_tokenize(sentence)\n",
    "\n",
    "after_using_lancaster = [lan.stem(t) for t in token]\n",
    "print(after_using_lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c45d54",
   "metadata": {},
   "source": [
    "will ---> wil \n",
    "\n",
    "take ---> tak\n",
    "####  These two words have no meaning in the English dictionary. \n",
    "\n",
    "#### And instead of 'care' it comes 'car' to the output with a completely different meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e861883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f764a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
