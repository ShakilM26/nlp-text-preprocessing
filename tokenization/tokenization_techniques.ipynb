{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f3a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import (TreebankWordTokenizer,\n",
    "                          word_tokenize,\n",
    "                          wordpunct_tokenize,\n",
    "                          TweetTokenizer,\n",
    "                          MWETokenizer)\n",
    "sentence = \"It's true, Ms. Martha Wayne! #Truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb1c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3836af00",
   "metadata": {},
   "source": [
    "## There are three types of tokenizations â€” sentence, word, and sub-word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18445a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d5cf712",
   "metadata": {},
   "source": [
    "### Whitespace tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177d045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whitespace tokenization: [\"It's\", 'true,', 'Ms.', 'Martha', 'Wayne!', '#Truth']\n"
     ]
    }
   ],
   "source": [
    "# This is the most simple and commonly used form of tokenization. \n",
    "# It splits the text whenever it finds whitespace characters. \n",
    "# but it's not the best option\n",
    "\n",
    "print(f'whitespace tokenization: {sentence.split()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a275a",
   "metadata": {},
   "source": [
    "### Punctuation-based tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5927befa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuation-based tokenization: ['It', \"'\", 's', 'true', ',', 'Ms', '.', 'Martha', 'Wayne', '!', '#', 'Truth']\n"
     ]
    }
   ],
   "source": [
    "print(f'punctuation-based tokenization: {wordpunct_tokenize(sentence)}')\n",
    "\n",
    "# looks like it's far better than whitespace tokenization\n",
    "# but Ms and (.) are should be attach together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2e54a",
   "metadata": {},
   "source": [
    "### Default/Treebankword tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ed68a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebank tokenization: ['It', \"'s\", 'true', ',', 'Ms.', 'Martha', 'Wayne', '!', '#', 'Truth']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "print(f'Treebank tokenization: {tokenizer.tokenize(sentence)}')\n",
    "\n",
    "# we can clearly see that "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364bbf71",
   "metadata": {},
   "source": [
    "### MWE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc76ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-word expression: ['My', 'name', 'is', 'Shakil_Targeryan', '.', 'King', 'of', 'the', 'Seven', 'Kingdoms', 'and', '3', 'Dragons', ',', 'Protector', 'of', 'the', 'realm', ',']\n"
     ]
    }
   ],
   "source": [
    "names = 'My name is Shakil Targeryan. King of the Seven Kingdoms and 3 Dragons, Protector of the realm, '\n",
    "mwe = MWETokenizer()\n",
    "mwe.add_mwe(('Shakil', 'Targeryan'))\n",
    "print(f'Multi-word expression: {mwe.tokenize(word_tokenize(names))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45022277",
   "metadata": {},
   "source": [
    "### Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cfd88aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet-rules based: [\"It's\", 'true', ',', 'Ms', '.', 'Martha', 'Wayne', '!', '#Truth']\n"
     ]
    }
   ],
   "source": [
    "token = TweetTokenizer()\n",
    "print(f'Tweet-rules based: {token.tokenize(sentence)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d03a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2938a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59b74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
